{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import firebirdsql\n",
    "from queue import Queue\n",
    "import concurrent.futures\n",
    "from openpyxl import Workbook\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Carregar variáveis de ambiente\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== Funções de Conexão =====================\n",
    "def get_firebird_connection():\n",
    "    # Ajuste os parâmetros conforme sua configuração, inclusive charset\n",
    "    return firebirdsql.connect(\n",
    "        host=os.getenv('HOST'),\n",
    "        port=int(os.getenv('PORT', '3050')),\n",
    "        database=os.getenv('DB_PATH'),\n",
    "        user=os.getenv('APP_USER'),\n",
    "        password=os.getenv('PASSWORD'),\n",
    "        role=os.getenv('ROLE'),\n",
    "        auth_plugin_name=os.getenv('AUTH'),\n",
    "        wire_crypt=False,\n",
    "        charset='ISO8859_1'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection_pool(pool_size=20):\n",
    "    \"\"\"\n",
    "    Cria um pool de conexões Firebird com pool_size fixo (20).\n",
    "    \"\"\"\n",
    "    pool = Queue(maxsize=pool_size)\n",
    "    for _ in range(pool_size):\n",
    "        conn = get_firebird_connection()\n",
    "        pool.put(conn)\n",
    "    return pool\n",
    "\n",
    "def get_connection_from_pool(pool):\n",
    "    # Fica bloqueado até ter uma conexão disponível no pool\n",
    "    return pool.get()\n",
    "\n",
    "def release_connection_to_pool(pool, conn):\n",
    "    # Devolve a conexão ao pool\n",
    "    pool.put(conn)\n",
    "    \n",
    "# ===================== Função para obter a quantidade total de registros =====================\n",
    "def get_total_count(pool):\n",
    "    \"\"\"\n",
    "    Retorna o número total de registros da tabela PRODUTO.\n",
    "    \"\"\"\n",
    "    conn = get_connection_from_pool(pool)\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT COUNT(*) FROM PRODUTO\")\n",
    "        count = cursor.fetchone()[0]\n",
    "        return count\n",
    "    finally:\n",
    "        release_connection_to_pool(pool, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== Função para carregar similares =====================\n",
    "def load_similars(pool):\n",
    "    \"\"\"\n",
    "    Executa a query para capturar os similares e monta um dicionário:\n",
    "      chave: p.NUMORIGINAL (produto)\n",
    "      valor: lista de s.NUMORIGINAL (similares)\n",
    "    \"\"\"\n",
    "    conn = get_connection_from_pool(pool)\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        query = \"\"\"\n",
    "            SELECT \n",
    "                p.NUMORIGINAL,  \n",
    "                s.NUMORIGINAL\n",
    "            FROM SIMILARIDADE s\n",
    "            JOIN PRODUTO p ON p.CDPRODUTO = s.CDPRODUTO\n",
    "            ORDER BY p.NUMORIGINAL\n",
    "        \"\"\"\n",
    "        cursor.execute(query)\n",
    "        rows = cursor.fetchall()\n",
    "        similar_dict = {}\n",
    "        for prod_num, similar_num in rows:\n",
    "            # Converte para string, caso não esteja\n",
    "            prod_key = str(prod_num)\n",
    "            similar_val = str(similar_num)\n",
    "            if prod_key in similar_dict:\n",
    "                similar_dict[prod_key].append(similar_val)\n",
    "            else:\n",
    "                similar_dict[prod_key] = [similar_val]\n",
    "        return similar_dict\n",
    "    finally:\n",
    "        release_connection_to_pool(pool, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== Função para buscar um \"chunk\" de registros =====================\n",
    "def fetch_chunk(offset, chunk_size, pool):\n",
    "    \"\"\"\n",
    "    Busca um pedaço (chunk) de registros da tabela PRODUTO.\n",
    "    \"\"\"\n",
    "    conn = get_connection_from_pool(pool)\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        query = (\n",
    "            \"SELECT FIRST {} SKIP {} CDPRODUTO, NUMORIGINAL, DESCRICAO, PRECOCUSTO, PRECOVENDA, \"\n",
    "            \"ESTOQUEPREVISTO, UNIDADE, NCM, LOCALIZACAO FROM PRODUTO\"\n",
    "        ).format(chunk_size, offset)\n",
    "        cursor.execute(query)\n",
    "        rows = cursor.fetchall()\n",
    "        return rows\n",
    "    finally:\n",
    "        release_connection_to_pool(pool, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== Mapeamento de cada registro para a linha do Excel =====================\n",
    "def process_record(db_row, current_date_str, similar_dict):\n",
    "    \"\"\"\n",
    "    Recebe uma tupla (db_row) com os campos extraídos da tabela PRODUTO:\n",
    "      db_row = (CDPRODUTO, NUMORIGINAL, DESCRICAO, PRECOCUSTO, PRECOVENDA,\n",
    "                ESTOQUEPREVISTO, UNIDADE, NCM, LOCALIZACAO)\n",
    "\n",
    "    Retorna uma lista com os valores mapeados conforme as regras:\n",
    "      - Campo 0 (CODIGO SEQUENCIAL): vazio\n",
    "      - Campo 1 (Nome da Empresa): \"comagro\"\n",
    "      - Campo 2 (CODIGO SEQUENCIAL DO ITEM): CDPRODUTO\n",
    "      - Campo 3 (NOME GRUPO): \"TEMPORARIO\"\n",
    "      - Campo 4 (NOME DESCRICAO): \"TEMPORARIO\"\n",
    "      - Campo 5 (NOME FABRICANTE): \"DIVERSOS\"\n",
    "      - Campo 6 (Nº FABRICANTE): NUMORIGINAL\n",
    "      - Campo 7 (CÓDIGO DE BARRAS - EAN 13): \"SEM GTIN\"\n",
    "      - Campo 8 (CÓDIGO DE BARRAS - qualquer formato): \"SEM GTIN\"\n",
    "      - Campo 9 (APLICAÇÃO DO PRODUTO): DESCRICAO\n",
    "      - Campo 10 (INFORMAÇÕES ADICIONAIS): string de similares no formato \"SIMILARES:xxx,yyy,zzz\"\n",
    "      - Campo 11 (Alíquota de IPI): 0\n",
    "      - Campo 12 (Situação tributária do IPI): \"060\"\n",
    "      - Campo 13 (Alíquota de ICMS na Entrada): vazio\n",
    "      - Campo 14 (Peso da peça): vazio\n",
    "      - Campo 15 (Unidade da peça): UNIDADE\n",
    "      - Campo 16 (Código ANP): vazio\n",
    "      - Campo 17 (Quantidade Embalagem de Compra): 1\n",
    "      - Campo 18 (Quantidade Embalagem de Venda): 1\n",
    "      - Campo 19 (Classificação Fiscal): NCM\n",
    "      - Campo 20 (Preço de tabela): vazio\n",
    "      - Campo 21 (Data do Preço de tabela): vazio\n",
    "      - Campo 22 (Data do Cadastro): data atual\n",
    "      - Campo 23 (Origem do Produto): 0\n",
    "      - Campo 24 (Situação Tributária do Item): \"00\"\n",
    "      - Campo 25 (Percentual da Alíquota ICMS): \"20,5%\"\n",
    "      - Campo 26 (Preço Custo): PRECOCUSTO\n",
    "      - Campo 27 (Preço venda): PRECOVENDA\n",
    "      - Campo 28 (Quantidade Estoque): ESTOQUEPREVISTO\n",
    "      - Campo 29 (Posição fixa do item): LOCALIZACAO\n",
    "      - Campos 30 a 37: vazios\n",
    "    \"\"\"\n",
    "    # Captura o produto (NUMORIGINAL) para buscar os similares\n",
    "    prod_num = str(db_row[1])\n",
    "    similares = similar_dict.get(prod_num, [])\n",
    "    if similares:\n",
    "        similar_field = \"SIMILARES:\" + \",\".join(similares)\n",
    "    else:\n",
    "        similar_field = \"\"\n",
    "\n",
    "    return [\n",
    "        \"\",                   # 0. CODIGO SEQUENCIAL (vazio)\n",
    "        \"COMAGRO\",            # 1. Nome da Empresa\n",
    "        db_row[0],            # 2. CODIGO SEQUENCIAL DO ITEM (CDPRODUTO)\n",
    "        \"TEMPORARIO\",         # 3. NOME GRUPO\n",
    "        \"TEMPORARIO\",         # 4. NOME DESCRICAO\n",
    "        \"DIVERSOS\",           # 5. NOME FABRICANTE\n",
    "        db_row[1],            # 6. Nº FABRICANTE (NUMORIGINAL)\n",
    "        \"SEM GTIN\",           # 7. CÓDIGO DE BARRAS (EAN 13)\n",
    "        \"SEM GTIN\",           # 8. CÓDIGO DE BARRAS (qualquer formato)\n",
    "        db_row[2],            # 9. APLICAÇÃO DO PRODUTO (DESCRICAO)\n",
    "        similar_field,        # 10. INFORMAÇÕES ADICIONAIS (similares)\n",
    "        0,                    # 11. Alíquota de IPI\n",
    "        \"060\",                # 12. Situação tributária do IPI\n",
    "        \"\",                   # 13. Alíquota de ICMS na Entrada (vazio)\n",
    "        \"\",                   # 14. Peso da peça (vazio)\n",
    "        db_row[6],            # 15. Unidade da peça (UNIDADE)\n",
    "        \"\",                   # 16. Código ANP (vazio)\n",
    "        1,                    # 17. Quantidade Embalagem de Compra\n",
    "        1,                    # 18. Quantidade Embalagem de Venda\n",
    "        db_row[7],            # 19. Classificação Fiscal (NCM)\n",
    "        \"\",                   # 20. Preço de tabela (vazio)\n",
    "        \"\",                   # 21. Data do Preço de tabela (vazio)\n",
    "        current_date_str,     # 22. Data do Cadastro\n",
    "        0,                    # 23. Origem do Produto\n",
    "        \"00\",                 # 24. Situação Tributária do Item\n",
    "        \"20,5%\",              # 25. Percentual da Alíquota ICMS\n",
    "        db_row[3],            # 26. Preço Custo (PRECOCUSTO)\n",
    "        db_row[4],            # 27. Preço venda (PRECOVENDA)\n",
    "        db_row[5],            # 28. Quantidade Estoque (ESTOQUEPREVISTO)\n",
    "        db_row[8],            # 29. Posição fixa do item (LOCALIZACAO)\n",
    "        \"\",                   # 30. Margem de Lucro do item (vazio)\n",
    "        \"\",                   # 31. Mkup para preço atacado (vazio)\n",
    "        \"\",                   # 32. Mkup para preço varejo (vazio)\n",
    "        \"\",                   # 33. Mkup Mínimo (vazio)\n",
    "        \"\",                   # 34. Estoque crítico (vazio)\n",
    "        \"\",                   # 35. Estoque máximo (vazio)\n",
    "        \"\",                   # 36. Quantidade de dias (máximo) (vazio)\n",
    "        \"\"                    # 37. Quantidade de dias (mínimo) (vazio)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de registros a extrair: 18883\n",
      "Processado chunk com offset 100 (tamanho: 100)\n",
      "Processado chunk com offset 400 (tamanho: 100)\n",
      "Processado chunk com offset 300 (tamanho: 100)\n",
      "Processado chunk com offset 0 (tamanho: 100)\n",
      "Processado chunk com offset 200 (tamanho: 100)\n",
      "Processado chunk com offset 500 (tamanho: 100)\n",
      "Processado chunk com offset 700 (tamanho: 100)\n",
      "Processado chunk com offset 600 (tamanho: 100)\n",
      "Processado chunk com offset 900 (tamanho: 100)\n",
      "Processado chunk com offset 800 (tamanho: 100)\n",
      "Processado chunk com offset 1000 (tamanho: 100)\n",
      "Processado chunk com offset 1100 (tamanho: 100)\n",
      "Processado chunk com offset 1300 (tamanho: 100)\n",
      "Processado chunk com offset 1200 (tamanho: 100)\n",
      "Processado chunk com offset 1400 (tamanho: 100)\n",
      "Processado chunk com offset 1500 (tamanho: 100)\n",
      "Processado chunk com offset 1600 (tamanho: 100)\n",
      "Processado chunk com offset 1700 (tamanho: 100)\n",
      "Processado chunk com offset 1800 (tamanho: 100)\n",
      "Processado chunk com offset 1900 (tamanho: 100)\n",
      "Processado chunk com offset 2000 (tamanho: 100)\n",
      "Processado chunk com offset 2100 (tamanho: 100)\n",
      "Processado chunk com offset 2200 (tamanho: 100)\n",
      "Processado chunk com offset 2300 (tamanho: 100)\n",
      "Processado chunk com offset 2400 (tamanho: 100)\n",
      "Processado chunk com offset 2600 (tamanho: 100)\n",
      "Processado chunk com offset 2700 (tamanho: 100)\n",
      "Processado chunk com offset 2800 (tamanho: 100)\n",
      "Processado chunk com offset 2500 (tamanho: 100)\n",
      "Processado chunk com offset 2900 (tamanho: 100)\n",
      "Processado chunk com offset 3000 (tamanho: 100)\n",
      "Processado chunk com offset 3100 (tamanho: 100)\n",
      "Processado chunk com offset 3200 (tamanho: 100)\n",
      "Processado chunk com offset 3400 (tamanho: 100)\n",
      "Processado chunk com offset 3300 (tamanho: 100)\n",
      "Processado chunk com offset 3500 (tamanho: 100)\n",
      "Processado chunk com offset 3600 (tamanho: 100)\n",
      "Processado chunk com offset 3700 (tamanho: 100)\n",
      "Processado chunk com offset 3800 (tamanho: 100)\n",
      "Processado chunk com offset 4000 (tamanho: 100)\n",
      "Processado chunk com offset 4100 (tamanho: 100)\n",
      "Processado chunk com offset 3900 (tamanho: 100)\n",
      "Processado chunk com offset 4200 (tamanho: 100)\n",
      "Processado chunk com offset 4300 (tamanho: 100)\n",
      "Processado chunk com offset 4400 (tamanho: 100)\n",
      "Processado chunk com offset 4500 (tamanho: 100)\n",
      "Processado chunk com offset 4600 (tamanho: 100)\n",
      "Processado chunk com offset 4700 (tamanho: 100)\n",
      "Processado chunk com offset 4800 (tamanho: 100)\n",
      "Processado chunk com offset 4900 (tamanho: 100)\n",
      "Processado chunk com offset 5000 (tamanho: 100)\n",
      "Processado chunk com offset 5200 (tamanho: 100)\n",
      "Processado chunk com offset 5100 (tamanho: 100)\n",
      "Processado chunk com offset 5300 (tamanho: 100)\n",
      "Processado chunk com offset 5400 (tamanho: 100)\n",
      "Processado chunk com offset 5500 (tamanho: 100)\n",
      "Processado chunk com offset 5600 (tamanho: 100)\n",
      "Processado chunk com offset 5700 (tamanho: 100)\n",
      "Processado chunk com offset 5800 (tamanho: 100)\n",
      "Processado chunk com offset 5900 (tamanho: 100)\n",
      "Processado chunk com offset 6000 (tamanho: 100)\n",
      "Processado chunk com offset 6100 (tamanho: 100)\n",
      "Processado chunk com offset 6300 (tamanho: 100)\n",
      "Processado chunk com offset 6400 (tamanho: 100)\n",
      "Processado chunk com offset 6200 (tamanho: 100)\n",
      "Processado chunk com offset 6500 (tamanho: 100)\n",
      "Processado chunk com offset 6600 (tamanho: 100)\n",
      "Processado chunk com offset 6700 (tamanho: 100)\n",
      "Processado chunk com offset 6900 (tamanho: 100)\n",
      "Processado chunk com offset 6800 (tamanho: 100)\n",
      "Processado chunk com offset 7000 (tamanho: 100)\n",
      "Processado chunk com offset 7100 (tamanho: 100)\n",
      "Processado chunk com offset 7200 (tamanho: 100)\n",
      "Processado chunk com offset 7400 (tamanho: 100)\n",
      "Processado chunk com offset 7300 (tamanho: 100)\n",
      "Processado chunk com offset 7500 (tamanho: 100)\n",
      "Processado chunk com offset 7600 (tamanho: 100)\n",
      "Processado chunk com offset 7700 (tamanho: 100)\n",
      "Processado chunk com offset 7800 (tamanho: 100)\n",
      "Processado chunk com offset 8000 (tamanho: 100)\n",
      "Processado chunk com offset 7900 (tamanho: 100)\n",
      "Processado chunk com offset 8200 (tamanho: 100)\n",
      "Processado chunk com offset 8100 (tamanho: 100)\n",
      "Processado chunk com offset 8300 (tamanho: 100)\n",
      "Processado chunk com offset 8400 (tamanho: 100)\n",
      "Processado chunk com offset 8600 (tamanho: 100)\n",
      "Processado chunk com offset 8500 (tamanho: 100)\n",
      "Processado chunk com offset 8700 (tamanho: 100)\n",
      "Processado chunk com offset 8900 (tamanho: 100)\n",
      "Processado chunk com offset 9000 (tamanho: 100)\n",
      "Processado chunk com offset 8800 (tamanho: 100)\n",
      "Processado chunk com offset 9100 (tamanho: 100)\n",
      "Processado chunk com offset 9400 (tamanho: 100)\n",
      "Processado chunk com offset 9300 (tamanho: 100)\n",
      "Processado chunk com offset 9500 (tamanho: 100)\n",
      "Processado chunk com offset 9200 (tamanho: 100)\n",
      "Processado chunk com offset 9700 (tamanho: 100)\n",
      "Processado chunk com offset 9800 (tamanho: 100)\n",
      "Processado chunk com offset 9900 (tamanho: 100)\n",
      "Processado chunk com offset 9600 (tamanho: 100)\n",
      "Processado chunk com offset 10000 (tamanho: 100)\n",
      "Processado chunk com offset 10200 (tamanho: 100)\n",
      "Processado chunk com offset 10300 (tamanho: 100)\n",
      "Processado chunk com offset 10400 (tamanho: 100)\n",
      "Processado chunk com offset 10100 (tamanho: 100)\n",
      "Processado chunk com offset 10500 (tamanho: 100)\n",
      "Processado chunk com offset 10700 (tamanho: 100)\n",
      "Processado chunk com offset 10600 (tamanho: 100)\n",
      "Processado chunk com offset 10800 (tamanho: 100)\n",
      "Processado chunk com offset 11000 (tamanho: 100)\n",
      "Processado chunk com offset 11200 (tamanho: 100)\n",
      "Processado chunk com offset 11100 (tamanho: 100)\n",
      "Processado chunk com offset 10900 (tamanho: 100)\n",
      "Processado chunk com offset 11300 (tamanho: 100)\n",
      "Processado chunk com offset 11400 (tamanho: 100)\n",
      "Processado chunk com offset 11500 (tamanho: 100)\n",
      "Processado chunk com offset 11600 (tamanho: 100)\n",
      "Processado chunk com offset 11700 (tamanho: 100)\n",
      "Processado chunk com offset 11900 (tamanho: 100)\n",
      "Processado chunk com offset 11800 (tamanho: 100)\n",
      "Processado chunk com offset 12000 (tamanho: 100)\n",
      "Processado chunk com offset 12200 (tamanho: 100)\n",
      "Processado chunk com offset 12300 (tamanho: 100)\n",
      "Processado chunk com offset 12400 (tamanho: 100)\n",
      "Processado chunk com offset 12500 (tamanho: 100)\n",
      "Processado chunk com offset 12100 (tamanho: 100)\n",
      "Processado chunk com offset 12700 (tamanho: 100)\n",
      "Processado chunk com offset 12600 (tamanho: 100)\n",
      "Processado chunk com offset 12900 (tamanho: 100)\n",
      "Processado chunk com offset 13000 (tamanho: 100)\n",
      "Processado chunk com offset 12800 (tamanho: 100)\n",
      "Processado chunk com offset 13100 (tamanho: 100)\n",
      "Processado chunk com offset 13200 (tamanho: 100)\n",
      "Processado chunk com offset 13300 (tamanho: 100)\n",
      "Processado chunk com offset 13500 (tamanho: 100)\n",
      "Processado chunk com offset 13600 (tamanho: 100)\n",
      "Processado chunk com offset 13400 (tamanho: 100)\n",
      "Processado chunk com offset 13900 (tamanho: 100)\n",
      "Processado chunk com offset 13700 (tamanho: 100)\n",
      "Processado chunk com offset 13800 (tamanho: 100)\n",
      "Processado chunk com offset 14100 (tamanho: 100)\n",
      "Processado chunk com offset 14200 (tamanho: 100)\n",
      "Processado chunk com offset 14300 (tamanho: 100)\n",
      "Processado chunk com offset 14000 (tamanho: 100)\n",
      "Processado chunk com offset 14600 (tamanho: 100)\n",
      "Processado chunk com offset 14400 (tamanho: 100)\n",
      "Processado chunk com offset 14500 (tamanho: 100)\n",
      "Processado chunk com offset 14700 (tamanho: 100)\n",
      "Processado chunk com offset 14800 (tamanho: 100)\n",
      "Processado chunk com offset 14900 (tamanho: 100)\n",
      "Processado chunk com offset 15100 (tamanho: 100)\n",
      "Processado chunk com offset 15200 (tamanho: 100)\n",
      "Processado chunk com offset 15400 (tamanho: 100)\n",
      "Processado chunk com offset 15300 (tamanho: 100)\n",
      "Processado chunk com offset 15500 (tamanho: 100)\n",
      "Processado chunk com offset 15600 (tamanho: 100)\n",
      "Processado chunk com offset 15000 (tamanho: 100)\n",
      "Processado chunk com offset 15800 (tamanho: 100)\n",
      "Processado chunk com offset 15900 (tamanho: 100)\n",
      "Processado chunk com offset 16000 (tamanho: 100)\n",
      "Processado chunk com offset 16100 (tamanho: 100)\n",
      "Processado chunk com offset 15700 (tamanho: 100)\n",
      "Processado chunk com offset 16200 (tamanho: 100)\n",
      "Processado chunk com offset 16300 (tamanho: 100)\n",
      "Processado chunk com offset 16400 (tamanho: 100)\n",
      "Processado chunk com offset 16600 (tamanho: 100)\n",
      "Processado chunk com offset 16800 (tamanho: 100)\n",
      "Processado chunk com offset 16700 (tamanho: 100)\n",
      "Processado chunk com offset 16500 (tamanho: 100)\n",
      "Processado chunk com offset 17000 (tamanho: 100)\n",
      "Processado chunk com offset 17100 (tamanho: 100)\n",
      "Processado chunk com offset 16900 (tamanho: 100)\n",
      "Processado chunk com offset 17500 (tamanho: 100)\n",
      "Processado chunk com offset 17200 (tamanho: 100)\n",
      "Processado chunk com offset 17400 (tamanho: 100)\n",
      "Processado chunk com offset 17300 (tamanho: 100)\n",
      "Processado chunk com offset 17700 (tamanho: 100)\n",
      "Processado chunk com offset 17800 (tamanho: 100)\n",
      "Processado chunk com offset 17900 (tamanho: 100)\n",
      "Processado chunk com offset 17600 (tamanho: 100)\n",
      "Processado chunk com offset 18100 (tamanho: 100)\n",
      "Processado chunk com offset 18000 (tamanho: 100)\n",
      "Processado chunk com offset 18200 (tamanho: 100)\n",
      "Processado chunk com offset 18400 (tamanho: 100)\n",
      "Processado chunk com offset 18600 (tamanho: 100)\n",
      "Processado chunk com offset 18500 (tamanho: 100)\n",
      "Processado chunk com offset 18300 (tamanho: 100)\n",
      "Processado chunk com offset 18800 (tamanho: 83)\n",
      "Processado chunk com offset 18700 (tamanho: 100)\n",
      "Total de registros processados: 18883\n",
      "Arquivo Excel salvo como 'produtos.xlsx'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===================== Função Principal =====================\n",
    "def main():\n",
    "    # Cria pool de conexões\n",
    "    pool = create_connection_pool(pool_size=20)\n",
    "    \n",
    "    # Carrega os similares (dicionário: chave = p.NUMORIGINAL, valor = lista de similares)\n",
    "    similar_dict = load_similars(pool)\n",
    "    \n",
    "    # Obtém a quantidade total de registros da tabela PRODUTO\n",
    "    total_count = get_total_count(pool)\n",
    "    print(f\"Total de registros a extrair: {total_count}\")\n",
    "    \n",
    "    # Define o tamanho do chunk (pode ser ajustado conforme volume de dados)\n",
    "    chunk_size = 100\n",
    "    offsets = range(0, total_count, chunk_size)\n",
    "    \n",
    "    # Data atual formatada (usada para \"Data do Cadastro\")\n",
    "    current_date_str = datetime.datetime.now().strftime(\"%d/%m/%Y\")\n",
    "    \n",
    "    all_data_rows = []  # aqui serão armazenadas todas as linhas processadas\n",
    "    \n",
    "    # Usa ThreadPoolExecutor para processar os chunks em paralelo\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        # Mapeia cada tarefa (chunk) com seu offset\n",
    "        future_to_offset = {\n",
    "            executor.submit(fetch_chunk, offset, chunk_size, pool): offset\n",
    "            for offset in offsets\n",
    "        }\n",
    "        for future in concurrent.futures.as_completed(future_to_offset):\n",
    "            offset = future_to_offset[future]\n",
    "            try:\n",
    "                chunk = future.result()\n",
    "                print(f\"Processado chunk com offset {offset} (tamanho: {len(chunk)})\")\n",
    "                # Para cada registro do chunk, mapeia para a linha do Excel\n",
    "                for db_row in chunk:\n",
    "                    excel_row = process_record(db_row, current_date_str, similar_dict)\n",
    "                    all_data_rows.append(excel_row)\n",
    "            except Exception as exc:\n",
    "                print(f\"Erro ao processar chunk com offset {offset}: {exc}\")\n",
    "    \n",
    "    print(f\"Total de registros processados: {len(all_data_rows)}\")\n",
    "    \n",
    "    # ===================== Criação do Excel =====================\n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "    \n",
    "    # Deixa as duas primeiras linhas em branco (para que você insira os cabeçalhos manualmente)\n",
    "    ws.append([])\n",
    "    ws.append([])\n",
    "    \n",
    "    # Insere as linhas de dados (cada linha já com 38 colunas)\n",
    "    for row in all_data_rows:\n",
    "        ws.append(row)\n",
    "    \n",
    "    # Salva o arquivo Excel\n",
    "    output_filename = \"produtos.xlsx\"\n",
    "    wb.save(output_filename)\n",
    "    print(f\"Arquivo Excel salvo como '{output_filename}'\")\n",
    "    \n",
    "    # Fecha todas as conexões do pool\n",
    "    while not pool.empty():\n",
    "        conn = pool.get()\n",
    "        conn.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
